%Lean preamble
\documentclass{article}
\usepackage[utf8x]{inputenc}
\usepackage{amssymb}

\usepackage{color}
\definecolor{keywordcolor}{rgb}{0.7, 0.1, 0.1}   % red
\definecolor{commentcolor}{rgb}{0.4, 0.4, 0.4}   % grey
\definecolor{symbolcolor}{rgb}{0.0, 0.1, 0.6}    % blue
\definecolor{sortcolor}{rgb}{0.1, 0.5, 0.1}      % green

\usepackage{listings}
\def\lstlanguagefiles{lstlean.tex}
\lstset{language=lean}

%My preamble
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsopn}
\usepackage{MnSymbol}

\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\nulls}{null}
\DeclareMathOperator{\spanf}{span}

%Black-board
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}

%Greek
\renewcommand{\a}{\alpha}
\newcommand{\z}{\zeta}
\renewcommand{\b}{\beta}
\newcommand{\g}{\gamma}
\newcommand{\e}{\varepsilon}
\renewcommand{\d}{\delta}
\renewcommand{\r}{\rho}
\renewcommand{\l}{\lambda}
\newcommand{\w}{\omega}
\newcommand{\n}{\eta}
\newcommand{\f}{\varphi}
\newcommand{\s}{\sigma}
\renewcommand{\t}{\tau}
\newcommand{\tr}{\tilde \rho}


\newcommand{\ct}{\texttt}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand*\mean[1]{\bar{#1}}

\usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,spacing=true,factor=1100,stretch=10,shrink=10]{microtype}

\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem*{prop*}{Proposition}
\newtheorem*{cor*}{Corollary}
\newcommand{\ud}{\, \mathrm{d}}

\author{Louis Carlin}
\title{Euclidean Domains in Lean}

\usepackage[pdftex]{hyperref}
\hypersetup{colorlinks,%
	    filecolor=black,%
	    citecolor=black,%
	    linkcolor=black}



\begin{document}
\maketitle
\newpage 

%TODO
%Do I call rings/EDs with the mathematical letters or lean letters?
%Citation system?

\section{An overview of Lean}

%how to tie type theory in?
\subsection{A quick look at type theory}
Lean is based on type-theoretic system, rather than the set theory traditionally used by most mathematicians. 
Initially, working with type theory is not too different to working with sets. 
We write $x:\a$ to mean ``$x$ is something of type $\a$'' rather than $x \in \a$ to mean ``$x$ is an element of $\a$''. 
We can also reason about many of the sets we are familiar with such as $\N$ or $\Z$ as types.

However, in type theory objects belong to a single type and are always identified as being of that type.
It is not possible to talk about an object $x$ in Lean without giving it a type.
Nor is it really possible to talk about something as being an object of more than one type.
So for example $5:\N$ and $5:\Z$ are distinct objects.
Luckily lean has a fairly versatile coercion system which allows us to convert between objects of different types, although it can be somewhat clunky at times.

We can build types out of other types, so for example $\a \to \beta$ is the type of functions from $\a$ to $\beta$. 
Lean's axiomatic system also extends simple type theory by implementing Types themselves as objects, meaning they themselves must have types.
So, for example \ct{$\N:$ Type} and \ct{Type : Type 1}.
In fact, in general \ct{Type $u$ : Type $(u+1)$}. 
This infinite type hierarchy is Lean's way of avoiding the contradictions brought about by ``the type of all types''.
%TODO this explanation is a bit weak

%Lean also allows for the creation of dependent types, which are essentially paremeterized types.
%So, for example a list of things of type $\a$ is of type \ct{list $\a$}.

The main advantage of type theory is that it is much easier to model computationally.
%TODO say more

\subsection{Propositions as types}
Lean also treats propositions as types. 
A proposition \ct{p : Prop} is the type of proofs of \ct{p}.
So when we say \ct{h : p}, we mean that \ct{h} is a proof of \ct{p}.
For example \ct{h : 5 > 3} is a proof that 5 is greater than 3.
To prove \ct{p}, it suffices to show we have something of type \ct{p} and thus if our proofs type-check correctly then they are valid\footnote{This is assuming there are no bugs in the Lean checker. The \href{https://github.com/leodemoura/lean/blob/master/doc/faq.md}{Lean FAQ} gives more details about the soundness of the kernel.}.

Under this paradigm of propositions as types, a proof that \ct{p : Prop} implies \ct{q : Prop} is the same as function that takes a proof of \ct{p} and gives a proof of \ct{q}.
This means that a proof of \ct{p $\implies$ q} is something of type \ct{p $\to$ q}, and thus we can write \ct{p $\to$ q} in place of \ct{p $\implies$ q}.
One other thing to note is that under the principle of ``proof irrelevance'' Lean treats all proofs of a proposition \ct{p} as definitionally equal, so any two proofs of \ct{p} are in effect the same.

\subsection{Lean Syntax} 

The most important notation to understand in Lean is function definition.
The following example is the ``if then else'' function as it appears in Lean.
The function takes a decidable proposition \ct{c} as input as well as return values \ct{t e : $\a$}.
If \ct{c} is true then it returns \ct{t}, otherwise it returns \ct{e}.
\begin{lstlisting}
def ite (c : Prop) [h : decidable c] {α : Sort u} (t e : α) : α 
:= decidable.rec_on h (λ hnc, e) (λ hc, t)
\end{lstlisting}
The \ct{def} keyword indicates the start of a definition and is followed by the name of the function \ct{ite}.
The parentheses \ct{(c : Prop)} indicate that the function takes a proposition \ct{c : Prop} as an explicit argument.
The square brackets indicate to Lean that what is between them is an input that Lean should be able to find for itself with its type class resolution system.
In this case \ct{decidable c} is an inductive type which either holds a proof that \ct{c} is true or that it isn't.
\begin{lstlisting}
class inductive decidable (p : Prop)
| is_false (h : ¬p) : decidable
| is_true  (h : p) : decidable

\end{lstlisting}
If Lean can't find an instance \ct{h : decidable c} for a given input \ct{c} then it will give an error message telling you type class resolution has failed.

Going back to the definition of \ct{ite}, the curly brackets \ct{\{$\a$ : Sort u\}} indicate that the argument inside them is implicit, which is to say it can be figured out from later arguments.
In this case $\a$ is the type of the final two arguments \ct{t e : $\a$}, so Lean is able to work out what you mean from the types of \ct{t} and \ct{e}.
The type after the colon is the return type of the function (in this case \ct{$\a$} since \ct{ite} will return \ct{t} or \ct{e}).
Finally, the part after the \ct{:=} is the definition of the function. 
In this case it makes use of a recursion principle \ct{rec\_on} which Lean defines automatically for inductive types.
The notation \ct{$\lambda$ hc, t} is how we write a function which takes an argument \ct{hc} and returns the value \ct{t}.
While normally we might have to write, \ct{$\lambda$ hc : c, t : $\a$}, Lean has enough information in this case to figure out these types itself so we can omit them.


%tactics mode (probably don't bother talking about monads)
\subsection{Tactics}
Writing out long proofs consisting entirely of anonymous $\lambda$ functions is time-consuming and finicky.
Lean does define some syntactic sugar to make proofs read more like traditional mathematical proofs.
For example, we can write \ct{assume hp : p,} instead of \ct{$\lambda$ hp : p}, and \ct{lemma} and \ct{theorem} are synonyms for \ct{def}.
However, the real strength of Lean in proving things is in tactics mode.

A tactic is basically an algorithm which automates repetitive tasks in proving things.
We tell Lean to enter tactics mode with a \ct{begin end} block.
Once in tactics mode Lean gives us a printout of the current context, which is what we know at that point in the proof. 
The turnstile symbol $\vdash$ indicates what we are trying to show.

Picture here!!!



%constructivism
\subsection{Constructivism}
%Constructive mathematicians do indeed reject LEM. But this does not mean they accept its negation!
Lean encourages a constructive approach to mathematics. 
This means that proofs usually give an explicit instance of the thing you are trying to prove and techniques like proof by contradiction are discouraged.
Lean does allow for the non-constructive axiom of choice, stating it as follows\footnote{Lean goes on to prove the more traditional set-theoretic statement of the axiom of choice using this axiom}: 
\begin{lstlisting}
/- the axiom -/
axiom choice {α : Sort u} : nonempty α → α
\end{lstlisting}
However, it must be imported from a file `classical.lean' in Lean's library, and proofs or functions which rely upon it must be marked as non-computable.

The law of the excluded middle follows from the axiom of choice in Lean's axiomatic system\footnote{see \url{https://en.wikipedia.org/wiki/Diaconescu\%27s\_theorem}} and is defined amongst other non-constructive principles as a theorem in `classical.lean'. 

While trying to avoid using the axiom of choice and law of the excluded middle was initially unintuitive to me it has the substantial advantage that anything you write in Lean without them is computable.
So for example my implementation of the Euclidean Algorithm is not just an abstract proof that such an algorithm exists, but can actually be executed in arbitrary Euclidean Domains.

\section{Euclidean domains}
What is a Euclidean Domain?

\subsection{Pre-existing structures in Lean}
A commutative ring is defined in lean as...

An Integral Domain extends this definition by...

\subsection{Defining Euclidean Domains in Lean}
I defined Euclidean Domains as...

%explicit vs non-explicit valuation (exists, trunc, inhabited)

%valuation being to natural numbers vs well-ordered set

%Do I talk about EF2 here?

\section{The Euclidean Algorithm}
%some history?

The Euclidean Algorithm is one of the main motivations of the definition of Euclidean Domains. 
It takes any two elements $a,b$ of a Euclidean Domain $R$ and gives a ``greatest common divisor'' of $a$ and $b$. 
An element $d \in R$ is a greatest common divisor of $a$ and $b$ if $d \divides a$, $d \divides b$ and $\forall x \in R, x \divides a \and x \divides b \implies x \divides d$.
We common write $\gcd(a,b)$ to denote a particular greatest common divisor of $a$ and $b$.
However it is important to note that greatest common divisors are not necessarily unique. In fact they are never unique in our definition of a Euclidean domain): if $d$ is a gcd of a $a$ and $b$ in a ring, then so is its additive inverse $-d$.

\subsection{The basic concept}

\subsection{The Extended Euclidean Algorithm}

\subsection{Well-foundedness}
%talk mostly about how things actually worked in Lean (factorial + something which doesn't work)

\subsection{The First implementation}
In defining the Euclidean Algorithm in Lean it was important to not only have it return the gcd as expected, but also to have a proof that what it returned \textit{was} the gcd. 
My first implementation of the Euclidean Algorithm satisfied this requirement by taking proofs as part of its input and returning a value paired with the fact that that value was actually a gcd. 
This is how I defined the input and output types:
\begin{lstlisting}
structure common_divisor {α : Type} [R: comm_ring α] (a b : α) :=
(value : α)
(divides_a : value ∣ a) 
(divides_b : value ∣ b)

structure greatest_common_divisor {α : Type} [R: comm_ring α] (a b : α) extends common_divisor a b :=
(greatest : ∀ d : common_divisor a b, d.value ∣ value)

/- this is the return type -/
structure bezout_identity {α : Type} [R: comm_ring α] (a b : α):= 
(x y : α) -- coefficients
(gcd : greatest_common_divisor a b)
(bezout : gcd.value = a * x + b * y)

/- this is the input type -/
structure eea_input {α : Type} (a b : α) [euclidean_domain α] := 
(rp rc xp xc yp yc: α)
(bezout_prev : rp = a * xp + b * yp)
(bezout_curr : rc = a * xc + b * yc)
(divides : ∀ x : α, x∣rp ∧ x∣rc → x∣a ∧ x∣b)
(greatest_divisor : ∀ d : common_divisor a b, d.value ∣ rp ∧ d.value ∣ rc)
\end{lstlisting}

This approach wasn't particularly good. The actual statement of the algorithm ended up being almost two pages long because I had to write the proof transforming the proofs I took as input to the proofs I needed to give as output. This meant that when I ran into issues (primarily trying to use non-computable valuations to show it was well-founded recursion) it was difficult to work out exactly where the problems were. It would also have been much less intuitive to have to work with the structure \ct{bezout\_identity} I defined than to be simply given a gcd and only given the proofs of its properties if you asked for them.

\subsection{The Second implementation}
My second implementation was much simpler. I modelled it off the gcd function for natural numbers which already existed in Lean's mathlib library. The function is defined as follows:
\begin{lstlisting}

\end{lstlisting}

%much simpler
%had to define an induction principle
%more modular
%talk about


\end{document}
